{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, pickle, os, numpy as np, news_loader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "from os import path, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_single(tokens, by_type=False):\n",
    "    \"\"\"\n",
    "    Gets the named entities in the list of tokens\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tokens: list(str)\n",
    "        a tokenized document containing named entities\n",
    "    by_type: bool, optional\n",
    "        whether or not differentiate between types of named entities\n",
    "        ***True currently not supported***\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out: list(str)\n",
    "        a list of the named entities in the document\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    pos = nltk.pos_tag(tokens) # label parts of speech\n",
    "    named_entities = nltk.ne_chunk(pos, binary=not by_type) # identify named entities\n",
    "    for i in range(0, len(named_entities)):\n",
    "        ents = named_entities.pop()\n",
    "        if getattr(ents, 'label', None) != None and ents.label() == \"NE\": \n",
    "            entities.append(([ne for ne in ents]))\n",
    "    extracted = np.array(entities)\n",
    "    if extracted.ndim == 3:\n",
    "        final = extracted[:,:,0].tolist()\n",
    "    else:\n",
    "        final = []\n",
    "        for entity in extracted:\n",
    "            final.append(np.array(entity)[:,0].tolist())\n",
    "    out = []\n",
    "    for entity in final:\n",
    "        entity = \" \".join(entity)\n",
    "        out.append(entity)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_database(filepath=DATABASE_FR):\n",
    "    \"\"\"\n",
    "    Initializes the global variable db with the database stored in the specfied filepath\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath: str (optional)\n",
    "        the directory and filename of the location of the database pickled txt file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        db: dict (str --> Counter)\n",
    "            the database mapping a named entity to the Counter \n",
    "            of co-occurences with other entities in the database\n",
    "    \"\"\"\n",
    "    global db\n",
    "    db = retrieve_database(filepath=filepath)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_single(extracted):\n",
    "    \"\"\"\n",
    "    Updates the database with the provided named entities in a single document\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    extracted: list(str)\n",
    "        a list of the named entities in the document\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    db: dict (str --> Counter)\n",
    "            the database mapping a named entity to the Counter \n",
    "            of co-occurences with other entities in the database\n",
    "    \"\"\"\n",
    "    counts = Counter(extracted)\n",
    "    for entity in extracted:\n",
    "        if entity in db:\n",
    "            db[entity].update(counts)\n",
    "            for key, value in counts.items():\n",
    "                if not key == entity:\n",
    "                    db[entity][key] = value * db[entity][entity]\n",
    "        else:\n",
    "            db[entity] = Counter(extracted)\n",
    "            for key, value in counts.items():\n",
    "                if not key == entity:\n",
    "                    db[entity][key] = value * db[entity][entity]\n",
    "        del db[entity][entity]\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATABASE_FR = \"data/entities_database.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_database(filepath=DATABASE_FR):\n",
    "    \"\"\"\n",
    "    Creates a new text file and folder in the filepath \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath: str (optional)\n",
    "        the directory and filename of the location of the database pickled txt file \n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(str.partition(filepath, \"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_database(filepath=DATABASE_FR):\n",
    "    \"\"\"\n",
    "    Saves the database to the text file in the specified file path\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath: str (optional)\n",
    "        the directory and filename of the location of the database pickled txt file \n",
    "    \"\"\"\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_database(filepath=DATABASE_FR):\n",
    "    \"\"\"\n",
    "    Retrieves the database from the text file in the specified file path\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath: str (optional)\n",
    "        the directory and filename of the location of the database pickled txt file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    db: dict (str --> Counter)\n",
    "            the database mapping a named entity to the Counter \n",
    "            of co-occurences with other entities in the database\n",
    "    \"\"\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        db = pickle.load(f)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_database(filepath=DATABASE_FR):\n",
    "    \"\"\"\n",
    "    Removes all entries in the database in the text file in the specified file path\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath: str (optional)\n",
    "        the directory and filename of the location of the database pickled txt file\n",
    "    \"\"\"\n",
    "    global db\n",
    "    db = defaultdict(Counter)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_related(entity, k=None):\n",
    "    \"\"\"\n",
    "    Finds the k entities most closely related to the query (an entity itself)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    entity: str\n",
    "        the entity which the results will be related to \n",
    "    k: int (optional)\n",
    "        the number of entities to be returned (default all matches)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out: list(str)\n",
    "        the k entities most closely related to the query\n",
    "    \"\"\"\n",
    "    out = db[entity].most_common(k)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(tokenlists):\n",
    "    \"\"\"\n",
    "    Updates the database with the provided named entities in multiple documents\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tokenlists: list(list(str))\n",
    "        a list of the named entities in the documents\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "     db: dict (str --> Counter)\n",
    "            the database mapping a named entity to the Counter \n",
    "            of co-occurences with other entities in the database\n",
    "    \"\"\"\n",
    "    for doc in tokenlists:\n",
    "        update_single(extract_single(doc))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_entities(tokenlists, k=None):\n",
    "    \"\"\"\n",
    "    Given a list of token-lists, return the k most common entities among them\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tokenlists: list(list(str))\n",
    "        a list of the named entities in the documents\n",
    "    k: int (optional)\n",
    "        the number of entities to be returned (default all matches)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    out: list(str)\n",
    "        the k entities most common in the documents\n",
    "    \"\"\"\n",
    "    matches = Counter()\n",
    "    for tokens in tokenlists:\n",
    "        extraction = extract_single(tokens)\n",
    "        matches.update(Counter(extraction))\n",
    "    out = matches.most_common(k)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
